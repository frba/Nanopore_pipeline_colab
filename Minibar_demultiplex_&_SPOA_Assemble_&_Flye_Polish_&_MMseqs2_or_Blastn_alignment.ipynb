{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frba/Nanopore_pipeline_colab/blob/main/Minibar_demultiplex_%26_SPOA_Assemble_%26_Flye_Polish_%26_MMseqs2_or_Blastn_alignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYmQkFzZ5Ve"
      },
      "source": [
        "#Pipeline for Nanopore Sequencing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LOLMiG1KFtHn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Step 1 - Upload files and Installing packages\n",
        "# @markdown Upload files:\n",
        "# @markdown 1. fastq files containing reads (raw data from plasmidsaurus)\n",
        "# @markdown 2. minibar barcode_file.txt - [example_barcode_file](https://liveconcordia.sharepoint.com/:t:/t/GenomeFoundryTeam/EQsYiSKVWo5Oli4UnBnkIEABReHpAAEuzrEk2Cypi6QlMw?e=1tqfym)\n",
        "# @markdown 3. fasta file containing the expected sequences - [example_fasta_template](https://liveconcordia.sharepoint.com/:u:/t/GenomeFoundryTeam/Eb9_w8lNcoFEmh9iUuME76EBpCtpj6ZHnsJcx9UtqFyuOQ?e=4SjzwQ)\n",
        "# @markdown 4. [Echo transfer.csv](https://liveconcordia.sharepoint.com/:x:/t/GenomeFoundryTeam/EYVzHEZPGb9DqxJDN56S_6kBc1_-whiPIm1jkmkiuh-U3A?e=tD3xl6) file (input file used in Echo)\n",
        "# @markdown 5. **Run the Step 1, it will crash and restart the runtime. Run it again and the following cells.**\n",
        "\n",
        "version = !conda --version\n",
        "if version[0] == \"/bin/bash: line 1: conda: command not found\":\n",
        "    !pip install -q condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "!conda config --add channels bioconda\n",
        "!conda install -c conda-forge -c bioconda mmseqs2\n",
        "!conda install -c bioconda blast\n",
        "!conda install flye\n",
        "!conda install -c bioconda seqkit\n",
        "%pip install biopython\n",
        "%pip install edlib\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "import subprocess\n",
        "import shutil\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MIGSCZ4AJ5Z0"
      },
      "outputs": [],
      "source": [
        "# @title Step 1.1 - Installing Tools\n",
        "# @markdown Installing Tools:\n",
        "# @markdown 1. SPOA (De novo assembler tool),\n",
        "# @markdown 2. Filtlong (Filtering tool), and\n",
        "# @markdown 3. Minibar (Demultiplex tool)\n",
        "\n",
        "!git clone https://github.com/rvaser/spoa\n",
        "%cd ./spoa\n",
        "!cmake -B build -DCMAKE_BUILD_TYPE=Release\n",
        "!make -C build\n",
        "%cd ..\n",
        "\n",
        "!curl https://raw.githubusercontent.com/calacademy-research/minibar/master/minibar.py > minibar.py\n",
        "!chmod +x minibar.py\n",
        "\n",
        "!git clone https://github.com/rrwick/Filtlong.git\n",
        "%cd ./Filtlong\n",
        "!make -j\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MdQnxARZkzv4"
      },
      "outputs": [],
      "source": [
        "#@title Step 2 - Set variable names (**Needs input from User**)\n",
        "\n",
        "#@markdown From the uploaded files, set the filename to each variable below:\n",
        "\n",
        "#@markdown *   barcodes_file  (a .txt file with sequences of barcodes' pair).\n",
        "#@markdown *   template_file (a .fasta file with template sequences).\n",
        "#@markdown *   echo transfer (a .csv file with the expected sequences).\n",
        "\n",
        "# prompt: combine multiple fastq files in one unique file\n",
        "# Assuming ONLY your raw fastq files are in the current directory\n",
        "\n",
        "!cat *.fastq >> merged_fastq_file.fastq # merge all raw data in one unique fastq file\n",
        "basecalled_file = 'merged_fastq_file.fastq' # do not modify this filename\n",
        "\n",
        "barcode_file = 'barcodes.txt' #<--- Rename input file\n",
        "template_file = 'genes.fasta' #<--- Rename input file\n",
        "echo_transfer = '410_echo_echo_transfer_draw_P2.csv' #<--- Rename input file\n",
        "\n",
        "if not os.path.exists(template_file):\n",
        "    print(f\"File {template_file} does not exist.\")\n",
        "if not os.path.exists(barcode_file):\n",
        "    print(f\"File {barcode_file} does not exist.\")\n",
        "if not os.path.exists(echo_transfer):\n",
        "    print(f\"File {echo_transfer} does not exist.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pcVIXgHyE2rl"
      },
      "outputs": [],
      "source": [
        "#@title Step 3 - Filtering with Filtlong (**Needs input from User**)\n",
        "\n",
        "#@markdown Filtering with Filtlong:\n",
        "\n",
        "#@markdown Set **min** and **max** length of the reads\n",
        "\n",
        "#@markdown _Filtlong will remove reads too small or too long from the raw data and return a file called filtered.fastq.gz_\n",
        "\n",
        "user_min_length = 400 #<--- PLEASE, CHECK THE ESTIMATED LENGTH!\n",
        "user_max_length = 800 #<--- PLEASE, CHECK THE ESTIMATED LENGTH!\n",
        "\n",
        "!Filtlong/bin/filtlong --min_length {user_min_length} --max_length {user_max_length} {basecalled_file} | gzip > filtered.fastq.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lfdmJIsspzhP"
      },
      "outputs": [],
      "source": [
        "#@title Step 4 - Demultiplexing with Minibar\n",
        "\n",
        "#@markdown Minibar will use the barcode.txt file + filtered.fastq.gz to demux the reads in bins as listed in barcode.txt file.\n",
        "\n",
        "!./minibar.py -e 4 -F -T -M 1 -P demux_minibar_1_ {barcode_file} filtered.fastq.gz\n",
        "\n",
        "!zip -R 'demultiplexed.zip' 'demux_minibar*' -qq\n",
        "!zip -R 'demultiplexed.zip' {barcode_file} -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DwbF8kpyjzN"
      },
      "source": [
        "## Step 5 - Stats information about the demultiplexed reads\n",
        "\n",
        "\n",
        "---\n",
        "####Step 5.2 Output table\n",
        "\n",
        " filename            | format | type |... | Q20(%)|... |\n",
        "--------------------|--------|------|----|-------|----|\n",
        "demux_FP1-RP1.fastaq| FASTQ  | DNA  |... | 88.21 |... |\n",
        "demux_FP1-RP2.fastaq| FASTQ  | DNA  |... | 96.79 |... |\n",
        "demux_FP1-RP3.fastaq| FASTQ  | DNA  |... | 79.44 |... |\n",
        "\n",
        "####Step 5.3 Output table\n",
        "\n",
        "filename            | seqid   | qual\n",
        "--------------------|---------|---------\n",
        "demux_FP1-RP1.fastaq| 974_ABC | 25.89\n",
        "demux_FP1-RP2.fastaq| 128_CDB | 30.01\n",
        "demux_FP1-RP3.fastaq| 579_CDB | 18.10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "-BcWZ9BcFOq7"
      },
      "outputs": [],
      "source": [
        "# @title Step 5.1 Count reads per barcode.\n",
        "\n",
        "# @markdown _Returns a file called count_barcodes.csv with a list of barcodes and number of reads in each._\n",
        "\n",
        "# @markdown Step can be deleted. Seqkit returns the number of reads and more information\n",
        "\n",
        "index = pd.read_csv(barcode_file, delimiter='\\t', index_col=0).index\n",
        "headers = [1,2,3,4]\n",
        "data = dict()\n",
        "for run in headers[:]:\n",
        "    data[run] = dict()\n",
        "    prefix = f'demux_minibar_{run}_'\n",
        "    file_list = glob.glob(f'{prefix}*')\n",
        "    for file in file_list:\n",
        "        sample=Path(file).stem[file.find(prefix)+len(prefix):]\n",
        "        count = len(list(SeqIO.parse(file, format='fastq')))\n",
        "        data[run][sample] = count\n",
        "\n",
        "pd.DataFrame(data).to_csv('count_barcodes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QQUyBOLqTFwS",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 5.2 Quality of reads by bin.\n",
        "\n",
        "#@markdown _Returns a file called quality_barcodes.csv with a list of barcodes and number of reads, and quality information (Q20%, Q30%, average quality) and more._\n",
        "\n",
        "def calculate_and_merge_quality():\n",
        "    \"\"\"Calculates quality of fastq files and merges the output into quality_barcodes.csv.\"\"\"\n",
        "\n",
        "    seqkit_cmd = f\"seqkit stats demux_minibar_1_*.fastq -a\"\n",
        "\n",
        "    result = subprocess.run(seqkit_cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    # Split the output into lines and process each line\n",
        "    lines = result.stdout.strip().split('\\n')\n",
        "\n",
        "    # Extract header and data\n",
        "    header = lines[0].split()\n",
        "    data = [line.split() for line in lines[1:]]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "    # Save DataFrame to CSV\n",
        "    df.to_csv('quality_barcodes.csv', index=False)\n",
        "\n",
        "calculate_and_merge_quality()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "f02jsn5noASB"
      },
      "outputs": [],
      "source": [
        "#@title 5.3 Quality of each read in a demux barcode pair.\n",
        "\n",
        "#@markdown _Returns a file called quality_reads.csv with a list of all reads in each barcode and average quality information._\n",
        "\n",
        "\n",
        "\n",
        "import io\n",
        "\n",
        "def run(fastq_file, references, i, j):\n",
        "    seqkit_cmd = f\"seqkit fx2tab {fastq_file} -n -q\"\n",
        "\n",
        "    # Run the seqkit command and capture the output\n",
        "    result = subprocess.run(seqkit_cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "    # Convert output to DataFrame and add filename column\n",
        "    df = pd.read_csv(io.StringIO(result.stdout), sep='\\t', header=None, names=['seq', 'qual'])\n",
        "    df.insert(0, 'file', fastq_file)  # Insert filename in the first column\n",
        "\n",
        "    # Append DataFrame to quality_reads.csv\n",
        "    if not os.path.isfile('quality_reads.csv'):\n",
        "        df.to_csv('quality_reads.csv', index=False, mode='w')\n",
        "    else:\n",
        "        df.to_csv('quality_reads.csv', index=False, header=False, mode='a')\n",
        "\n",
        "\n",
        "for i in range(1, 10):  # Changed to range(1, 2) to iterate once\n",
        "  for j in range(1, 10):  # Changed to range(1, 2) to iterate once\n",
        "    reads_path = f\"demux_minibar_1_FP{i}-RP{j}.fastq\"\n",
        "    if os.path.exists(reads_path):\n",
        "        run(reads_path, template_file, i, j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGFPfJmDwi0Z"
      },
      "source": [
        "##Step 6 - De Novo Consensus\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "SypYO6hhHYeA"
      },
      "outputs": [],
      "source": [
        "#@title Step 6.1 - Assemble with SPOA\n",
        "\n",
        "files = glob.glob('demux_minibar_*.fastq')\n",
        "for file in files:\n",
        "    cmd = f'./spoa/build/bin/spoa {file} > {file.replace(\"fastq\", \"fasta\")}'\n",
        "    !{cmd}\n",
        "\n",
        "#Compress output files in assembled.zip\n",
        "!zip -R 'assembled.zip' 'demux_*.fasta' -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "i32FUTQmJ5dU"
      },
      "outputs": [],
      "source": [
        "#@title Step 6.2 - Polishing consensus with Flye **(Needs User input)**\n",
        "\n",
        "#@markdown Variable **estimated_size** needs to be updated!!\n",
        "\n",
        "#@markdown _Fasta files with consensus will be polished by Flye and return a file *_polished.fasta and a zipfile polished.zip_\n",
        "\n",
        "user_estimated_size = 600 #<---- PLEASE, CHECK THE ESTIMATED LENGTH!\n",
        "\n",
        "for i in range(1, 21):\n",
        "  for j in range(1, 21):\n",
        "    reads_path = f\"demux_minibar_1_FP{i}-RP{j}.fastq\" #Filtered and demultiplexed reads\n",
        "    write_path = f\"flye_output_FP{i}-RP{j}\" #Folder name\n",
        "    polish_target = f\"demux_minibar_1_FP{i}-RP{j}.fasta\" #Output file from SPOA\n",
        "    estimated_size = user_estimated_size #Estimated size of the reads\n",
        "\n",
        "    if os.path.exists(reads_path):\n",
        "      flye_command = f\"flye --nano-hq {reads_path} --out-dir {write_path} --genome-size {estimated_size} --meta --keep-haplotypes --polish-target {polish_target}\"\n",
        "\n",
        "      try:\n",
        "          # Run the flye command, capture stderr, and check for errors\n",
        "          result = subprocess.run(flye_command, shell=True, check=True, capture_output=True, text=True)\n",
        "          #print(result.stdout)  # Print standard output if successful\n",
        "      except subprocess.CalledProcessError as e:\n",
        "          print(f\"Error running Flye: {e}\")\n",
        "          print(f\"Flye stderr output:\\n{e.stderr}\")  # Print standard error for debugging\n",
        "\n",
        "      #Move the polished file once it has been created\n",
        "      !mv \"{write_path}/polished_1.fasta\" \"{polish_target.replace(\".fasta\", \"_polished.fasta\")}\"\n",
        "      #print(f\"Polished file: {polish_target}\")\n",
        "\n",
        "# Delete all folders starting with \"flye_output\" and their contents\n",
        "for folder_name in glob.glob(\"flye_output*\"):\n",
        "    shutil.rmtree(folder_name)\n",
        "\n",
        "# Delete files ending with *.fai\n",
        "for file in glob.glob(\"*.fai\"):\n",
        "    os.remove(file)\n",
        "\n",
        "print(\"Polishing done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CltiVLAoJ5eq"
      },
      "outputs": [],
      "source": [
        "#@title Step 6.3 - Rename seqid with filename\n",
        "\n",
        "#@markdown _After running SPOA the seqid in the fasta files is renamed to: 'consensus'._\n",
        "\n",
        "#@markdown _To keep the trackability of the reads, it needs to be renamed with the filename._\n",
        "\n",
        "#@markdown _This step will rename all *_polished.fasta's seqid with their filename._\n",
        "\n",
        "files = glob.glob('*_polished.fasta')\n",
        "\n",
        "for file in files:\n",
        "    name = file.replace('.fasta', '')\n",
        "    record = SeqIO.read(file, 'fasta')\n",
        "    record.id = name\n",
        "    record.name = name\n",
        "    record.description = 'filtered with Filtlong, assembled with SPOA and polish with Flye'\n",
        "    SeqIO.write(record, file, 'fasta')\n",
        "\n",
        "# Create a zip file named 'polished.zip'\n",
        "with zipfile.ZipFile('polished.zip', 'w') as zipf:\n",
        "    # Find all files ending with '_polished.fasta'\n",
        "    for file in glob.glob(\"*_polished.fasta\"):\n",
        "        # Add each file to the zip archive\n",
        "        zipf.write(file)\n",
        "print(f\"Files added to polished.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41-23yGYrWIT"
      },
      "source": [
        "##Step 7 - Alignment Tools\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aXQhwTwQEQT",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 7.1 Run MMSeqs (Sequence Alignment)\n",
        "\n",
        "#@markdown AlignResult.tsv (All alignment combinations)\n",
        "\n",
        "# prompt: mmseq_cmd = f\"mmseqs easy-search mmseq_query.fa {references} AlignResult.tsv tmp --search-type 3\"\n",
        "# add columns name in the output file\n",
        "def run_mmseq(queries, references):\n",
        "    for query in queries:\n",
        "        !cat {query} >> mmseq_query.fa # merge all *_polished.fasta in one unique file to use it as input for mmseqs2\n",
        "\n",
        "    mmseq_cmd = f\"mmseqs easy-search mmseq_query.fa {references} AlignResult_mmseqs.tsv tmp --search-type 3 --format-mode 4\"\n",
        "\n",
        "    # Run the mmseqs command\n",
        "    !{mmseq_cmd}\n",
        "\n",
        "run_mmseq(glob.glob('*_polished.fasta'), template_file)\n",
        "\n",
        "print(\"Alignment done! AlignResult_mmseqs.tsv created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJrd9yxaQDNE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 7.2 - Run NCBI Blastn\n",
        "\n",
        "#@markdown _returns a called blast_results.tsv_\n",
        "\n",
        "def run_blastn(queries, references):\n",
        "\n",
        "    if not os.path.exists(\"mmseq_query.fa\"):\n",
        "      for query in queries:\n",
        "          !cat {query} >> mmseq_query.fa # merge all *_polished.fasta in one unique file to use it as input for blastn\n",
        "\n",
        "    # Create a database file with the templates\n",
        "    blastdb_cmd = f\"makeblastdb -in {template_file} -out blastdb -dbtype nucl\"\n",
        "    !{blastdb_cmd}\n",
        "\n",
        "    # Run BlastN and output a file: blast_results.tsv\n",
        "    blast_cmd = f\"blastn -query mmseq_query.fa -db blastdb -out AlignResult_blastn.tsv -outfmt '6 std qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore sseq'\"\n",
        "    !{blast_cmd}\n",
        "\n",
        "run_blastn(glob.glob('*_polished.fasta'), template_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjKCG-KDV0Kd"
      },
      "source": [
        "## Step 8 - Pos processing the Alignment file\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2ymnfwTDOVrB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 8.1 - Add quality information from seqkit in the alignment file\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the two DataFrames\n",
        "df1 = pd.read_csv('quality_barcodes.csv', index_col='file')\n",
        "df2 = pd.read_csv('AlignResult_mmseqs.tsv', sep='\\t')\n",
        "\n",
        "# Extract the substring for merging\n",
        "df1['barcode'] = df1.index.str.extract(r'demux_minibar_1_(.*).fastq', expand=False)\n",
        "df2['barcode'] = df2['query'].str.extract(r'demux_minibar_1_(.*)_polished', expand=False)\n",
        "\n",
        "# Merge DataFrames\n",
        "merged_df = pd.merge(df2, df1, on='barcode', how='left')\n",
        "\n",
        "# Rename columns for clarity\n",
        "merged_df = merged_df.rename(columns={'num_seqs': 'read_count', 'AvgQual': 'avg_quality'})\n",
        "\n",
        "# Save the merged DataFrame\n",
        "merged_df.to_csv('AlignResult_mmseqs_quality.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Step 8.2 - Sort by bitscore and remove duplicates (gene and barcodes)\n",
        "\n",
        "all_hits = pd.read_csv('AlignResult_mmseqs_quality.tsv', sep='\\t')\n",
        "\n",
        "# Drop duplicates of templates\n",
        "top_hits = all_hits.sort_values(by='bits', ascending=False).drop_duplicates(subset='target')\n",
        "top_hits.to_csv('TopAlignments_bygene.tsv', sep='\\t', index=False)\n",
        "print('TopAlignments_bygene.csv created!')\n",
        "\n",
        "# Drop duplicates of barcodes\n",
        "top_hits = all_hits.sort_values(by='bits', ascending=False).drop_duplicates(subset='query')\n",
        "top_hits.to_csv('TopAlignments_bybarcode.tsv', sep='\\t', index=False)\n",
        "print('TopAlignments_bybarcode.csv created!')"
      ],
      "metadata": {
        "id": "ax-ZUNexecIP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "UvDE5kGdhw_B",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Step 8.3 - Add Plate Well information in Top Alignments\n",
        "\n",
        "\n",
        "# prompt: Looking into a .csv file called *echo_transfer\n",
        "# search the barcode (FP1-RP1) split them by -\n",
        "# And search in the csv file that looks like this:\n",
        "# Sample_ID, Sample Name, Source Plate, Source Plate Name, Source Well, Destination Plate Name, Destination Well, Volume,\n",
        "# pY108_FP1_1, pY108_FP_1, GF0001254, MOTY_OL_001, A1, GF0001264, GF0001264, A1, 25\n",
        "# pY108_RP1_1, pY108_RP_1, GF0001254, MOTY_OL_001, C1, GF0001264, GF0001264, A1, 25\n",
        "# pY108_FP1_1, pY108_FP_1, GF0001254, MOTY_OL_001, A1, GF0001264, GF0001264, A2, 25\n",
        "# pY108_RP2_1, pY108_RP_1, GF0001254, MOTY_OL_001, C1, GF0001264, GF0001264, A2, 25\n",
        "# The barcode FP1-RP1 will be separated like this: FP1 and RP1 will share the same Destination Well + Destination Plate Name.\n",
        "# For each barcode in ToAlignments_2.tsv check in the *echo_transfer* the Destination Plate Name and Destination Well and add the information in the TopAlignments_2.tsv\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def add_tsv_zip():\n",
        "  # Create a zip file named 'alignment.zip'\n",
        "  with zipfile.ZipFile('alignment.zip', 'w') as zipf:\n",
        "      # Find all files ending with '*.tsv'\n",
        "      for file in glob.glob(\"*.tsv\"):\n",
        "          # Add each file to the zip archive\n",
        "          zipf.write(file)\n",
        "  print(f\"Files added to alignment.zip\")\n",
        "\n",
        "\n",
        "def add_plate_well(top_alignments_file):\n",
        "\n",
        "  # Load the TopAlignments_2.tsv file\n",
        "  top_alignments = pd.read_csv(top_alignments_file, sep='\\t')\n",
        "\n",
        "  # Load the echo_transfer.csv file\n",
        "  echo_transfer_file = pd.read_csv(echo_transfer)\n",
        "\n",
        "    # Function to extract FP and RP barcodes from qseqid\n",
        "  def extract_barcodes(barcode):\n",
        "    # Check if barcode is a string before splitting\n",
        "    if isinstance(barcode, str):\n",
        "      fp_barcode = barcode.split('-')[0]\n",
        "      rp_barcode = barcode.split('-')[1]\n",
        "      return fp_barcode, rp_barcode\n",
        "    else:\n",
        "      # Handle cases where barcode is not a string (e.g., NaN)\n",
        "      return None, None  # Or raise an exception if preferred\n",
        "\n",
        "  # Add new columns for Destination Plate Name and Destination Well\n",
        "  top_alignments['Destination Plate Name'] = None\n",
        "  top_alignments['Destination Well'] = None\n",
        "  top_alignments['Sample Name'] = None\n",
        "\n",
        "  # Iterate through the TopAlignments_2.tsv file\n",
        "  for index, row in top_alignments.iterrows():\n",
        "    fp_barcode, rp_barcode = extract_barcodes(row['barcode'])\n",
        "\n",
        "    if fp_barcode and rp_barcode:\n",
        "      # Search for matching barcodes in echo_transfer.csv\n",
        "      matching_rows_fp = echo_transfer_file[echo_transfer_file['Sample Name'].str.contains(fp_barcode)]\n",
        "      matching_rows_rp = echo_transfer_file[echo_transfer_file['Sample Name'].str.contains(rp_barcode)]\n",
        "\n",
        "      # Check if both barcodes have matches\n",
        "      if not matching_rows_fp.empty and not matching_rows_rp.empty:\n",
        "        # Find common Destination Plate Name and Destination Well\n",
        "        common_rows = pd.merge(\n",
        "          matching_rows_fp[['Destination Plate Name', 'Destination Well']],\n",
        "          matching_rows_rp[['Destination Plate Name', 'Destination Well']],\n",
        "          on=['Destination Plate Name', 'Destination Well'],\n",
        "          how='inner'\n",
        "        )\n",
        "\n",
        "        if not common_rows.empty:\n",
        "          # Get the first common row (assuming there's only one)\n",
        "          first_common_row = common_rows.iloc[0]\n",
        "          top_alignments.at[index, 'Destination Plate Name'] = first_common_row['Destination Plate Name']\n",
        "          top_alignments.at[index, 'Destination Well'] = first_common_row['Destination Well']\n",
        "\n",
        "          # Filter echo_transfer for matching plate and well, excluding barcode-containing Sample Names\n",
        "          filtered_echo_transfer = echo_transfer_file[\n",
        "              (echo_transfer_file['Destination Plate Name'] == first_common_row['Destination Plate Name']) &\n",
        "              (echo_transfer_file['Destination Well'] == first_common_row['Destination Well']) &\n",
        "              (~echo_transfer_file['Sample Name'].str.contains(fp_barcode)) &\n",
        "              (~echo_transfer_file['Sample Name'].str.contains(rp_barcode))\n",
        "          ]\n",
        "\n",
        "          # Get the first Sample Name from the filtered DataFrame\n",
        "          if not filtered_echo_transfer.empty:\n",
        "              top_alignments.at[index, 'Sample Name'] = filtered_echo_transfer['Sample Name'].iloc[0]\n",
        "\n",
        "  # Reorder columns to place Destination Plate Name and Destination Well at the beginning\n",
        "  cols = ['Destination Plate Name', 'Destination Well', 'Sample Name'] + [col for col in top_alignments.columns if col not in ['Destination Plate Name', 'Destination Well', 'Sample Name']]\n",
        "  top_alignments = top_alignments[cols]\n",
        "\n",
        "  # Save the updated TopAlignments.tsv file\n",
        "  top_alignments.to_csv(top_alignments_file, sep='\\t', index=False)\n",
        "\n",
        "\n",
        "# Call the function for both files\n",
        "add_plate_well('TopAlignments_bygene.tsv')\n",
        "add_plate_well('TopAlignments_bybarcode.tsv')\n",
        "add_tsv_zip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-qwlVmG0nwXc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Step 9 - Clean up temp files\n",
        "# Delete all *.fasta files after adding them to the zip\n",
        "for file in glob.glob(\"*.fasta\"):\n",
        "    os.remove(file)\n",
        "\n",
        "# Delete all *.tsv files after adding them to the zip\n",
        "for file in glob.glob(\"*.tsv\"):\n",
        "    os.remove(file)\n",
        "    #print(f\"Deleted file: {file}\")\n",
        "\n",
        "# Delete all *.fastq files after adding them to the zip\n",
        "for file in glob.glob(\"*.fastq\"):\n",
        "    os.remove(file)\n",
        "    #print(f\"Deleted file: {file}\")\n",
        "\n",
        "# Delete all blastdb.* files\n",
        "for file in glob.glob(\"blastdb.*\"):\n",
        "    os.remove(file)\n",
        "    #print(f\"Deleted file: {file}\")\n",
        "\n",
        "# Delete all *.stats files\n",
        "for file in glob.glob(\"*.stats\"):\n",
        "    os.remove(file)\n",
        "    #print(f\"Deleted file: {file}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}